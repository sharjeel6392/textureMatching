{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "question1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnTqe4qjvlO9"
      },
      "source": [
        "# JUPYTER NOTEBOOK FOR HOMEWORK 2 - question 1\n",
        "Extracting texture features and matching them for scene classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly59WE7YvlPG",
        "outputId": "b0af03f4-afdd-471a-9a01-40e4f90e8173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "!pip install pandas\n",
        "!pip install tqdm\n",
        "!pip install -U scikit-learn\n",
        "!pip install -U scikit-image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.16.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.2 threadpoolctl-2.1.0\n",
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 334kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2020.9.3)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-image\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "Successfully installed scikit-image-0.17.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRZsxJLOwg9y",
        "outputId": "b3673b6c-9fb2-4d3d-8d37-3a50f729e6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVR2NNkPvlP8"
      },
      "source": [
        "import os, glob, time, sys\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
        "from skimage import io, transform\n",
        "from skimage.filters.edges import convolve\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler #use for data normalization\n",
        "\n",
        "from makeLMfilters import makeLMfilters\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kka6wJMwvlQh"
      },
      "source": [
        "## 1. Load the training and testing images from the two .CSV files respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdskkXJsvlQm"
      },
      "source": [
        "#Load the data along with the class labels\n",
        "# Note, you will need to use the file folder name to determine the label of an image\n",
        "# Convert the images to grayscale and resize them to 128 x 128\n",
        "# (Optional) You might want to save your data here (to avoid repeating this step)\n",
        "\n",
        "trainData = []\n",
        "trainLabel = []\n",
        "testData = []\n",
        "testLabel = []\n",
        "\n",
        "k = 0\n",
        "\n",
        "trainFile = open('train250.csv', newline='')\n",
        "testFile = open('test250.csv', newline='')\n",
        "trainReader = csv.reader(trainFile, delimiter=' ')\n",
        "testReader = csv.reader(testFile, delimiter=' ')\n",
        "    \n",
        "for row in trainReader:\n",
        "    if (k>0):\n",
        "        data = row[0].split(',')\n",
        "        image = io.imread(data[0], as_gray=True)\n",
        "        trainData.append(transform.resize(image,(128,128)))\n",
        "        trainLabel.append(data[1])\n",
        "    else:\n",
        "        k+=1\n",
        "\n",
        "k = 0\n",
        "for row in testReader:\n",
        "    if (k>0):\n",
        "        data = row[0].split(',')\n",
        "        image = io.imread(data[0])\n",
        "        testData.append(transform.resize(image,(128,128)))\n",
        "        testLabel.append(data[1])\n",
        "    else:\n",
        "        k+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znBTTFBxvlQ8"
      },
      "source": [
        "## 2. Apply a bank of filters and generate features for training, testing and save the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ4iFcWovlQ_"
      },
      "source": [
        "#. Using the overcomplete bank of filters F provided, convolve your input image with each filter in the bank\n",
        "#  (make sure you check the dimensions of the returned array)\n",
        "#\n",
        "\n",
        "def getAbsFilterResponses( F, imggray ):\n",
        "    \n",
        "    rows, cols = imggray.shape\n",
        "    num_filters = F.shape[2]\n",
        "    responses = np.zeros((rows, cols, num_filters))   \n",
        "    \n",
        "    #. Convolve the input image with every filter in the bank of filters \n",
        "    #   to get a response array; take the absolute value of the values in the array\n",
        "\n",
        "    for i in range(num_filters):\n",
        "        filter = F[:,:,i]\n",
        "        image = convolve(imggray, filter)\n",
        "        responses[:,:,i] = image\n",
        "    \n",
        "    img_responses = np.absolute(responses)\n",
        "    return img_responses\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXD7lvhyvlRT"
      },
      "source": [
        "def apply_filter_bank( df, label, desc ):\n",
        "    print(desc)\n",
        "    F = makeLMfilters() # This creates the over-complete bank of filters F\n",
        "    X = np.array([])    # Initialize the numpy array to stack the responses for each image\n",
        "    y = []              # The label for each image\n",
        "    \n",
        "    length = len(df)\n",
        "    Xtemp = []\n",
        "\n",
        "    for i in range(length):\n",
        "      image = df[i]\n",
        "      x = getAbsFilterResponses(F, image)\n",
        "      Xtemp.append(x)\n",
        "      y = [label[i] for i in range(0,length)]\n",
        "    \n",
        "    X = np.array(Xtemp)\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "KnoSs5YpvlRm",
        "outputId": "2818260a-9bb1-4c90-dbfd-3e8c61b360c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## generate training and testing features, save them in a pickle with joblib\n",
        "# NOTE: The code in this cell has been written for you\n",
        "# NOTE2: This process can take a VERY LONG TIME...\n",
        "#\n",
        "\n",
        "X_train, y_train = apply_filter_bank( trainData, trainLabel, 'Training -> ' )\n",
        "X_test, y_test = apply_filter_bank( testData, testLabel, 'Testing -> ' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training -> \n",
            "Testing -> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUz-2DStvlR1",
        "outputId": "60df6d31-e04a-41d3-9ce4-ab23c48e3570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# save the dataset, pickle using joblib\n",
        "dataset = f'data.pkl'\n",
        "obj = {\n",
        "    'train': {\n",
        "        'features': X_train,\n",
        "        'label': y_train\n",
        "    },\n",
        "    'test': {\n",
        "        'features': X_test,\n",
        "        'label': y_test\n",
        "    }\n",
        "}\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "with open( dataset, 'wb' ) as f:\n",
        "    joblib.dump( obj, f, compress=3 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(250, 128, 128, 48)\n",
            "(250, 128, 128, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPnEjm92vlSC"
      },
      "source": [
        "Load back the dataset (optional)\n",
        "## 3. Run Kmeans with k=500 (recommended)\n",
        "save the model again (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "eIKZrUpgvlSE",
        "outputId": "8b0f8ff5-a4bc-4e09-eda4-eaca99134fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# load back the dataset (optional)\n",
        "# NOTE: The code in this cell has been written for you\n",
        "dataset = f'data.pkl'\n",
        "with open( dataset, 'rb' ) as f:\n",
        "    obj = joblib.load( f )\n",
        "print ( 'finished loading pkl file back')\n",
        "    \n",
        "X_train, y_train = obj['train']['features'], obj['train']['label']\n",
        "X_test, y_test = obj['test']['features'], obj['test']['label']\n",
        "print( f'X_train shape: {X_train.shape}; y_train shape: {len(y_train)}; X_test shape: {X_test.shape}; y_test shape: {len(y_test)}' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished loading pkl file back\n",
            "X_train shape: (250, 128, 128, 48); y_train shape: 250; X_test shape: (250, 128, 128, 48); y_test shape: 250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "kmfMywiLvlSS",
        "outputId": "d3e6a19b-02bd-43bc-f62d-47f9ac18ff76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Vectorize the training set \n",
        "# NOTE: The vectorization code has been written for you below\n",
        "reshape_X_train = X_train.reshape( -1, 48 )\n",
        "print( f'Training dataset shape: {reshape_X_train.shape}' )\n",
        "\n",
        "# normalize the the reshaped data (recommended to use MinMaxScaler)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(reshape_X_train)\n",
        "scaled = scaler.transform(reshape_X_train)\n",
        "\n",
        "\n",
        "# run kmeans (because the data is large, recommended to run minibatch kmeans)\n",
        "# NOTE: This process can take a VERY LONG TIME...\n",
        "\n",
        "kmeans = MiniBatchKMeans(n_clusters=500, batch_size=300).fit(scaled)\n",
        "\n",
        "# save kmeans model (optional)\n",
        "# NOTE: The data saving code has been written for you below\n",
        "model = f'kmeans_model.pkl'\n",
        "with open( model, 'wb' ) as f:\n",
        "    joblib.dump( kmeans, f, compress=3 )\n",
        "print( f'Kmeans model saved.' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset shape: (4096000, 48)\n",
            "Kmeans model saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox2VT2tQvlSf"
      },
      "source": [
        "## 4. Generate the frequency histogram (feature) for each image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f8uH4ylvlSi"
      },
      "source": [
        "# load the model (optional)\n",
        "model = f'kmeans_model.pkl'\n",
        "with open( model, 'rb' ) as f:\n",
        "    kmeans = joblib.load( f )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMG4BGGKvlS1"
      },
      "source": [
        "# Given an image response (already filtered) and the kmeans model, compute its frequency histogram\n",
        "# a) Vectorize the response image\n",
        "# b) Max-min normalize the response\n",
        "# c) Predict clusters for each 48-dimensional pixel using the k-means predict function\n",
        "# d) Generate the frequency histogram by incrementing the cluster centers where each pixel belongs\n",
        "# e) Normalize the resulting frequency histogram so that it sums to 1\n",
        "def calc_freq( img, kmeans ):\n",
        "\n",
        "    reshape_img = img.reshape( -1, 48 )\n",
        "\n",
        "    scaled = scaler.transform(reshape_img)\n",
        "    \n",
        "    y = kmeans.predict(scaled)\n",
        "    hist = np.zeros(500)\n",
        "\n",
        "    for i in range(len(y)):\n",
        "      hist[y[i]] += 1\n",
        "    \n",
        "    img_hist= [float(i)/sum(hist) for i in hist]\n",
        "    return img_hist #this is the histogram feature representing an image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "RD6Mc22ovlTG",
        "outputId": "d9bbfa42-0b24-4441-a436-8134727ab122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# loop through the set and call calc_freq on each image in the set (training and testing)\n",
        "\n",
        "histTrain = []\n",
        "histTest = []\n",
        "\n",
        "print(\"Generating histogram for train set...\")\n",
        "for image in X_train:\n",
        "    hist = calc_freq(image, kmeans)\n",
        "    histTrain.append(hist)\n",
        "\n",
        "print(\"Generating histogram for test set...\")\n",
        "for image in X_test:\n",
        "    hist = calc_freq(image, kmeans)\n",
        "    histTest.append(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating histogram for train set...\n",
            "Generating histogram for test set...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwYVdqkQvlTc"
      },
      "source": [
        "## 5. Implement the \"nearest neighbor classifier\" by comparing each image in Testing with the reference training images to generate a label.\n",
        "Compare using chi-square distance measure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW5MsixLvlTg"
      },
      "source": [
        "# Implement a function to calculate chi-square distance between 2 histograms ref and img\n",
        "#\n",
        "def calc_chi_sq( ref, img ):\n",
        "    length = len(ref)\n",
        "    dist = 0\n",
        "    for i in range(length):\n",
        "        numerator = (ref[i] - img[i])**2\n",
        "        denominator = ref[i] + img[i]\n",
        "        if denominator != 0:\n",
        "            dist += (numerator/denominator)\n",
        "    \n",
        "    dist = 0.5*dist    \n",
        "    \n",
        "    return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "dxitGVO0vlTx"
      },
      "source": [
        "# Using the chi-sq distances between each img in training\n",
        "# and each image in test, find the closest match for each test img in training, \n",
        "#  assign the label of the closest match to that test img\n",
        "# Your output will be 'y_pred', the array of predicted test labels.\n",
        "\n",
        "y_pred = []\n",
        "for i in range(len(histTest)):\n",
        "    testImage = histTest[i]\n",
        "    minDist = 999999\n",
        "    yPred = -1\n",
        "    for j in range(len(histTrain)):\n",
        "        trainImage = histTrain[j]\n",
        "        dist = calc_chi_sq(testImage, trainImage)\n",
        "        if dist < minDist:\n",
        "            minDist = dist\n",
        "            yPred = y_train[j]\n",
        "    y_pred.append(yPred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nsn6rpcvlT-"
      },
      "source": [
        "## 6. Generate a class confusion matrix and print out your accuracy specifically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuBL0PtdvlUA",
        "outputId": "08f7fde9-1e27-4248-98d3-bd561abc1d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Using y_test (true labels on the test data) and y_pred (the predicted labels), \n",
        "#  call the appropriate library function to display your confusion matrix, \n",
        "#  ensuring that the labels corectly match up with the folder names given\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     01beach       0.72      0.52      0.60        25\n",
            "    02forest       0.50      0.60      0.55        25\n",
            "  03mountain       0.30      0.24      0.27        25\n",
            "      04city       0.35      0.24      0.29        25\n",
            "    05suburb       0.54      0.52      0.53        25\n",
            "    06street       0.59      0.64      0.62        25\n",
            "   07bedroom       0.38      0.32      0.35        25\n",
            "   08kitchen       0.35      0.36      0.35        25\n",
            "09livingroom       0.32      0.40      0.36        25\n",
            "     10store       0.36      0.52      0.43        25\n",
            "\n",
            "    accuracy                           0.44       250\n",
            "   macro avg       0.44      0.44      0.43       250\n",
            "weighted avg       0.44      0.44      0.43       250\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65M1E_sLF4cW",
        "outputId": "633028ca-53fa-4229-c466-151aefe574da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "length = len(y_pred)\n",
        "count = 0\n",
        "\n",
        "for i in range(length):\n",
        "  if(y_pred[i] == y_test[i]):\n",
        "    count += 1\n",
        "\n",
        "print(count/length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.436\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}